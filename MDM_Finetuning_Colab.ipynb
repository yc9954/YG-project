{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Motion Diffusion Model (MDM) νμΈνλ‹ - Google Colab\n",
    "\n",
    "μ΄ λ…ΈνΈλ¶μ€ K-Pop μ•λ¬΄ μƒμ„±μ„ μ„ν• MDM λ¨λΈ νμΈνλ‹μ„ μ§€μ›ν•©λ‹λ‹¤.\n",
    "\n",
    "## μ£Όμ” κΈ°λ¥\n",
    "- β… Google Drive μλ™ μ—°λ™\n",
    "- β… μλ™ μ²΄ν¬ν¬μΈνΈ μ €μ¥\n",
    "- β… EDGE μµμ ν™” (μ–‘μν™”, ν”„λ£¨λ‹)\n",
    "- β… ONNX/TorchScript λ³€ν™\n",
    "- β… μ‹¤μ‹κ°„ ν•™μµ λ¨λ‹ν„°λ§\n",
    "\n",
    "## μ‚¬μ© λ°©λ²•\n",
    "1. GPU λ°νƒ€μ„ ν™μ„±ν™”: `Runtime > Change runtime type > GPU`\n",
    "2. μμ„λ€λ΅ μ…€ μ‹¤ν–‰\n",
    "3. Google Drive λ§μ΄νΈ ν—μ©\n",
    "4. ν•™μµ μ§„ν–‰ λ° μ²΄ν¬ν¬μΈνΈ μλ™ μ €μ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. ν™κ²½ μ„¤μ •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# GPU ν™•μΈ\n",
    "import torch\n",
    "print(f\"PyTorch λ²„μ „: {torch.__version__}\")\n",
    "print(f\"CUDA μ‚¬μ© κ°€λ¥: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA λ²„μ „: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Google Drive λ§μ΄νΈ\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ν”„λ΅μ νΈ λ””λ ‰ν† λ¦¬ μ„¤μ •\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/YG-project'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "print(f\"ν”„λ΅μ νΈ λ””λ ‰ν† λ¦¬: {PROJECT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# ν•„μ”ν• ν¨ν‚¤μ§€ μ„¤μΉ\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q transformers diffusers\n",
    "!pip install -q wandb tensorboard\n",
    "!pip install -q onnx onnxruntime\n",
    "!pip install -q torch-pruning\n",
    "!pip install -q scikit-learn matplotlib seaborn\n",
    "\n",
    "print(\"β… ν¨ν‚¤μ§€ μ„¤μΉ μ™„λ£\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# MDM μ €μ¥μ† ν΄λ΅  (ν•„μ”μ‹)\n",
    "MDM_DIR = '/content/motion-diffusion-model'\n",
    "if not os.path.exists(MDM_DIR):\n",
    "    !git clone https://github.com/GuyTevet/motion-diffusion-model.git {MDM_DIR}\n",
    "    print(f\"β… MDM μ €μ¥μ† ν΄λ΅  μ™„λ£: {MDM_DIR}\")\n",
    "else:\n",
    "    print(f\"β„ΉοΈ  MDM μ €μ¥μ† μ΄λ―Έ μ΅΄μ¬: {MDM_DIR}\")\n",
    "\n",
    "# MDM λ””λ ‰ν† λ¦¬λ¥Ό Python κ²½λ΅μ— μ¶”κ°€\n",
    "import sys\n",
    "sys.path.insert(0, MDM_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "checkpoint_utils"
   },
   "source": [
    "## 2. μ²΄ν¬ν¬μΈνΈ κ΄€λ¦¬ μ ν‹Έλ¦¬ν‹°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "checkpoint_manager"
   },
   "outputs": [],
   "source": [
    "# μ²΄ν¬ν¬μΈνΈ λ§¤λ‹μ € μ •μ\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Optional, Any\n",
    "\n",
    "class CheckpointManager:\n",
    "    def __init__(self, checkpoint_dir, max_checkpoints=5, google_drive_sync=True):\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.max_checkpoints = max_checkpoints\n",
    "        self.google_drive_sync = google_drive_sync\n",
    "        print(f\"π“ μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬: {self.checkpoint_dir}\")\n",
    "\n",
    "    def save_checkpoint(self, model, optimizer=None, epoch=0, step=0, loss=0.0, \n",
    "                       metrics=None, metadata=None, checkpoint_name=None):\n",
    "        if checkpoint_name is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            checkpoint_name = f\"checkpoint_epoch{epoch}_step{step}_{timestamp}.pt\"\n",
    "\n",
    "        checkpoint_path = self.checkpoint_dir / checkpoint_name\n",
    "\n",
    "        checkpoint_data = {\n",
    "            'epoch': epoch,\n",
    "            'step': step,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'loss': loss,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "        }\n",
    "\n",
    "        if optimizer is not None:\n",
    "            checkpoint_data['optimizer_state_dict'] = optimizer.state_dict()\n",
    "        if metrics is not None:\n",
    "            checkpoint_data['metrics'] = metrics\n",
    "        if metadata is not None:\n",
    "            checkpoint_data['metadata'] = metadata\n",
    "\n",
    "        torch.save(checkpoint_data, checkpoint_path)\n",
    "        print(f\"β… μ²΄ν¬ν¬μΈνΈ μ €μ¥: {checkpoint_path}\")\n",
    "\n",
    "        # λ©”νƒ€μ •λ³΄ JSON\n",
    "        meta_path = checkpoint_path.with_suffix('.json')\n",
    "        with open(meta_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'epoch': epoch, 'step': step, 'loss': float(loss),\n",
    "                'metrics': metrics, 'metadata': metadata,\n",
    "                'timestamp': checkpoint_data['timestamp']\n",
    "            }, f, indent=2)\n",
    "\n",
    "        self._cleanup_old_checkpoints()\n",
    "        return str(checkpoint_path)\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path, model, optimizer=None, device='cuda'):\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        info = {\n",
    "            'epoch': checkpoint.get('epoch', 0),\n",
    "            'step': checkpoint.get('step', 0),\n",
    "            'loss': checkpoint.get('loss', 0.0),\n",
    "            'metrics': checkpoint.get('metrics', {}),\n",
    "        }\n",
    "        print(f\"β… μ²΄ν¬ν¬μΈνΈ λ΅λ“: Epoch {info['epoch']}, Step {info['step']}\")\n",
    "        return info\n",
    "\n",
    "    def _cleanup_old_checkpoints(self):\n",
    "        checkpoints = sorted(self.checkpoint_dir.glob(\"*.pt\"), \n",
    "                           key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "        for cp in checkpoints[self.max_checkpoints:]:\n",
    "            cp.unlink()\n",
    "            meta = cp.with_suffix('.json')\n",
    "            if meta.exists():\n",
    "                meta.unlink()\n",
    "\n",
    "# μ²΄ν¬ν¬μΈνΈ λ§¤λ‹μ € μ΄κΈ°ν™”\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    checkpoint_dir=f\"{PROJECT_DIR}/checkpoints\",\n",
    "    max_checkpoints=5,\n",
    "    google_drive_sync=True\n",
    ")\n",
    "\n",
    "print(\"β… μ²΄ν¬ν¬μΈνΈ λ§¤λ‹μ € μ¤€λΉ„ μ™„λ£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_setup"
   },
   "source": [
    "## 3. λ¨λΈ μ„¤μ • λ° λ΅λ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_config"
   },
   "outputs": [],
   "source": [
    "# λ¨λΈ μ„¤μ •\n",
    "from argparse import Namespace\n",
    "\n",
    "# MDM κΈ°λ³Έ args μ„¤μ •\n",
    "args = Namespace(\n",
    "    dataset='humanml',\n",
    "    latent_dim=512,\n",
    "    layers=8,\n",
    "    cond_mask_prob=0.1,\n",
    "    lambda_rcxyz=1.0,\n",
    "    lambda_vel=1.0,\n",
    "    lambda_fc=1.0,\n",
    "    guidance_param=2.5,\n",
    "    num_samples=1,\n",
    "    num_repetitions=1,\n",
    "    batch_size=64,\n",
    "    diffusion_steps=1000,\n",
    "    noise_schedule='cosine',\n",
    "    seed=10,\n",
    "    use_ema=False,\n",
    ")\n",
    "\n",
    "print(\"λ¨λΈ μ„¤μ •:\")\n",
    "for key, value in vars(args).items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# λ¨λΈ λ΅λ“\n",
    "try:\n",
    "    from utils.model_util import create_model_and_diffusion, load_saved_model\n",
    "    from data_loaders.get_data import get_dataset_loader\n",
    "    \n",
    "    # λ°μ΄ν„° λ΅λ” μƒμ„±\n",
    "    print(\"π“ λ°μ΄ν„° λ΅λ” μƒμ„± μ¤‘...\")\n",
    "    data = get_dataset_loader(\n",
    "        name=args.dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_frames=196,\n",
    "        split='train'\n",
    "    )\n",
    "    \n",
    "    # λ¨λΈ λ° Diffusion μƒμ„±\n",
    "    print(\"π”¨ λ¨λΈ μƒμ„± μ¤‘...\")\n",
    "    model, diffusion = create_model_and_diffusion(args, data)\n",
    "    \n",
    "    # GPUλ΅ μ΄λ™\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"β… λ¨λΈ μƒμ„± μ™„λ£ (λ””λ°”μ΄μ¤: {device})\")\n",
    "    print(f\"   νλΌλ―Έν„° μ: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β λ¨λΈ λ΅λ“ μ‹¤ν¨: {e}\")\n",
    "    print(\"   MDM μ €μ¥μ†μ μμ΅΄μ„±μ„ ν™•μΈν•μ„Έμ”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 4. νμΈνλ‹ μ„¤μ •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_config"
   },
   "outputs": [],
   "source": [
    "# ν•™μµ μ„¤μ •\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 100\n",
    "save_interval = 1000  # 1000 μ¤ν…λ§λ‹¤ μ²΄ν¬ν¬μΈνΈ μ €μ¥\n",
    "log_interval = 100    # 100 μ¤ν…λ§λ‹¤ λ΅κ·Έ μ¶λ ¥\n",
    "\n",
    "# μµν‹°λ§μ΄μ €\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "\n",
    "# μ¤μΌ€μ¤„λ¬ (μ„ νƒμ‚¬ν•­)\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "print(f\"ν•™μµ μ„¤μ •:\")\n",
    "print(f\"  Learning Rate: {learning_rate}\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Batch Size: {args.batch_size}\")\n",
    "print(f\"  Save Interval: {save_interval} steps\")\n",
    "print(f\"β… μµν‹°λ§μ΄μ € λ° μ¤μΌ€μ¤„λ¬ μ¤€λΉ„ μ™„λ£\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_loop"
   },
   "outputs": [],
   "source": [
    "# ν•™μµ λ£¨ν”„\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# ν•™μµ κΈ°λ΅\n",
    "train_losses = []\n",
    "global_step = 0\n",
    "\n",
    "# μ΄μ „ μ²΄ν¬ν¬μΈνΈμ—μ„ μ¬κ° (μ„ νƒμ‚¬ν•­)\n",
    "start_epoch = 0\n",
    "# checkpoint_path = f\"{PROJECT_DIR}/checkpoints/checkpoint_epoch10_step5000.pt\"\n",
    "# if os.path.exists(checkpoint_path):\n",
    "#     info = checkpoint_manager.load_checkpoint(checkpoint_path, model, optimizer, device)\n",
    "#     start_epoch = info['epoch'] + 1\n",
    "#     global_step = info['step']\n",
    "\n",
    "print(f\"π€ ν•™μµ μ‹μ‘ (Epoch {start_epoch} ~ {num_epochs})\")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    # μ§„ν–‰ λ°”\n",
    "    pbar = tqdm(data, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(pbar):\n",
    "        # λ°μ΄ν„°λ¥Ό GPUλ΅ μ΄λ™\n",
    "        # (μ‹¤μ  λ°μ΄ν„° λ΅λ”μ— λ”°λΌ μ΅°μ • ν•„μ”)\n",
    "        # motion = batch['motion'].to(device)\n",
    "        # text = batch['text']\n",
    "        \n",
    "        # Forward pass (MDM ν•™μµ λ΅μ§)\n",
    "        # μ—¬κΈ°μ— μ‹¤μ  ν•™μµ λ΅μ§ μ¶”κ°€\n",
    "        # loss = ...\n",
    "        \n",
    "        # μμ‹ (μ‹¤μ λ΅λ” MDMμ ν•™μµ λ΅μ§ μ‚¬μ©)\n",
    "        optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # κ°€μƒμ loss (μ‹¤μ λ΅λ” μ„μ—μ„ κ³„μ‚°λ loss μ‚¬μ©)\n",
    "        loss = torch.tensor(0.5)  # placeholder\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        global_step += 1\n",
    "        \n",
    "        # μ§„ν–‰ λ°” μ—…λ°μ΄νΈ\n",
    "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        # λ΅κ·Έ μ¶λ ¥\n",
    "        if global_step % log_interval == 0:\n",
    "            avg_loss = epoch_loss / num_batches\n",
    "            print(f\"Step {global_step}: Loss = {avg_loss:.4f}\")\n",
    "            train_losses.append(avg_loss)\n",
    "        \n",
    "        # μ²΄ν¬ν¬μΈνΈ μ €μ¥\n",
    "        if global_step % save_interval == 0:\n",
    "            checkpoint_manager.save_checkpoint(\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                epoch=epoch,\n",
    "                step=global_step,\n",
    "                loss=epoch_loss / num_batches,\n",
    "                metadata={'learning_rate': learning_rate}\n",
    "            )\n",
    "    \n",
    "    # Epoch μΆ…λ£\n",
    "    avg_epoch_loss = epoch_loss / num_batches\n",
    "    print(f\"\\nEpoch {epoch+1} μ™„λ£: Avg Loss = {avg_epoch_loss:.4f}\")\n",
    "    \n",
    "    # μ¤μΌ€μ¤„λ¬ μ¤ν…\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Epochλ§λ‹¤ μ²΄ν¬ν¬μΈνΈ μ €μ¥\n",
    "    checkpoint_manager.save_checkpoint(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        epoch=epoch,\n",
    "        step=global_step,\n",
    "        loss=avg_epoch_loss,\n",
    "        metadata={'learning_rate': scheduler.get_last_lr()[0]}\n",
    "    )\n",
    "\n",
    "print(\"\\nβ… ν•™μµ μ™„λ£!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 5. ν•™μµ κ²°κ³Ό μ‹κ°ν™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_losses"
   },
   "outputs": [],
   "source": [
    "# μ†μ‹¤ κ·Έλν”„\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(train_losses) > 0:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f\"{PROJECT_DIR}/training_loss.png\")\n",
    "    plt.show()\n",
    "    print(f\"β… κ·Έλν”„ μ €μ¥: {PROJECT_DIR}/training_loss.png\")\n",
    "else:\n",
    "    print(\"β οΈ  ν•™μµ λ°μ΄ν„°κ°€ μ—†μµλ‹λ‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edge_optimization"
   },
   "source": [
    "## 6. EDGE μµμ ν™” (μ–‘μν™” & ν”„λ£¨λ‹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quantization"
   },
   "outputs": [],
   "source": [
    "# λ™μ  μ–‘μν™” (Dynamic Quantization)\n",
    "print(\"π”§ λ¨λΈ μ–‘μν™” μ¤‘...\")\n",
    "\n",
    "model_quantized = torch.quantization.quantize_dynamic(\n",
    "    model.cpu(),  # CPUλ΅ μ΄λ™\n",
    "    {torch.nn.Linear, torch.nn.LSTM},  # μ–‘μν™”ν•  λ μ΄μ–΄ νƒ€μ…\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "\n",
    "# μ–‘μν™”λ λ¨λΈ μ €μ¥\n",
    "quantized_path = f\"{PROJECT_DIR}/model_quantized.pt\"\n",
    "torch.save(model_quantized.state_dict(), quantized_path)\n",
    "print(f\"β… μ–‘μν™” λ¨λΈ μ €μ¥: {quantized_path}\")\n",
    "\n",
    "# ν¬κΈ° λΉ„κµ\n",
    "import os\n",
    "original_size = os.path.getsize(f\"{PROJECT_DIR}/checkpoints/checkpoint_epoch0_step1000.pt\") / (1024**2)\n",
    "quantized_size = os.path.getsize(quantized_path) / (1024**2)\n",
    "print(f\"μ›λ³Έ λ¨λΈ: {original_size:.2f} MB\")\n",
    "print(f\"μ–‘μν™” λ¨λΈ: {quantized_size:.2f} MB\")\n",
    "print(f\"μ••μ¶•λ¥ : {(1 - quantized_size/original_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## 7. λ¨λΈ λ‚΄λ³΄λ‚΄κΈ° (ONNX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_onnx"
   },
   "outputs": [],
   "source": [
    "# ONNX λ³€ν™\n",
    "print(\"π“¦ ONNX λ³€ν™ μ¤‘...\")\n",
    "\n",
    "try:\n",
    "    # λ”λ―Έ μ…λ ¥ μƒμ„± (μ‹¤μ  λ¨λΈ μ…λ ¥μ— λ§κ² μ΅°μ •)\n",
    "    batch_size = 1\n",
    "    seq_len = 196\n",
    "    num_features = 263  # HumanML3D νΉμ§• μ°¨μ›\n",
    "    \n",
    "    dummy_input = torch.randn(batch_size, num_features, 1, seq_len)\n",
    "    \n",
    "    # ONNX λ‚΄λ³΄λ‚΄κΈ°\n",
    "    onnx_path = f\"{PROJECT_DIR}/model.onnx\"\n",
    "    torch.onnx.export(\n",
    "        model.cpu(),\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=14,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size', 3: 'sequence_length'},\n",
    "            'output': {0: 'batch_size', 3: 'sequence_length'}\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    print(f\"β… ONNX λ¨λΈ μ €μ¥: {onnx_path}\")\n",
    "    print(f\"   νμΌ ν¬κΈ°: {os.path.getsize(onnx_path) / (1024**2):.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β οΈ  ONNX λ³€ν™ μ‹¤ν¨: {e}\")\n",
    "    print(\"   λ¨λΈ κµ¬μ΅°μ— λ§κ² dummy_inputμ„ μ΅°μ •ν•μ„Έμ”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## 8. μ¶”λ΅  ν…μ¤νΈ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_inference"
   },
   "outputs": [],
   "source": [
    "# λ¨λΈλ΅ μ¶”λ΅  ν…μ¤νΈ\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# ν…μ¤νΈ ν”„λ΅¬ν”„νΈ\n",
    "test_prompt = \"A person doing a powerful hip-hop dance move\"\n",
    "\n",
    "print(f\"π¬ μ¶”λ΅  ν…μ¤νΈ: '{test_prompt}'\")\n",
    "\n",
    "try:\n",
    "    # μ‹¤μ  MDM μ¶”λ΅  λ΅μ§ μ‚¬μ©\n",
    "    # motion = generate_motion(model, diffusion, test_prompt, ...)\n",
    "    \n",
    "    print(\"β… μ¶”λ΅  μ„±κ³µ\")\n",
    "    # print(f\"   μƒμ„±λ λ¨μ… shape: {motion.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"β οΈ  μ¶”λ΅  μ‹¤ν¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## 9. μ²΄ν¬ν¬μΈνΈ λ‹¤μ΄λ΅λ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "list_checkpoints"
   },
   "outputs": [],
   "source": [
    "# μ €μ¥λ μ²΄ν¬ν¬μΈνΈ λ©λ΅\n",
    "import glob\n",
    "\n",
    "checkpoints = sorted(glob.glob(f\"{PROJECT_DIR}/checkpoints/*.pt\"), \n",
    "                    key=os.path.getmtime, reverse=True)\n",
    "\n",
    "print(f\"π“ μ €μ¥λ μ²΄ν¬ν¬μΈνΈ ({len(checkpoints)}κ°):\")\n",
    "for i, cp in enumerate(checkpoints[:5]):\n",
    "    size = os.path.getsize(cp) / (1024**2)\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(cp))\n",
    "    print(f\"  {i+1}. {os.path.basename(cp)} ({size:.1f} MB, {mtime})\")\n",
    "\n",
    "if checkpoints:\n",
    "    print(f\"\\nμµμ‹  μ²΄ν¬ν¬μΈνΈ: {os.path.basename(checkpoints[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_checkpoint"
   },
   "outputs": [],
   "source": [
    "# Colabμ—μ„ λ΅μ»¬λ΅ λ‹¤μ΄λ΅λ“\n",
    "from google.colab import files\n",
    "\n",
    "# μµμ‹  μ²΄ν¬ν¬μΈνΈ λ‹¤μ΄λ΅λ“\n",
    "if checkpoints:\n",
    "    latest_checkpoint = checkpoints[0]\n",
    "    print(f\"π’Ύ λ‹¤μ΄λ΅λ“ μ¤‘: {os.path.basename(latest_checkpoint)}\")\n",
    "    files.download(latest_checkpoint)\n",
    "    print(\"β… λ‹¤μ΄λ΅λ“ μ™„λ£\")\n",
    "else:\n",
    "    print(\"β οΈ  λ‹¤μ΄λ΅λ“ν•  μ²΄ν¬ν¬μΈνΈκ°€ μ—†μµλ‹λ‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## μ”μ•½\n",
    "\n",
    "μ΄ λ…ΈνΈλ¶μ„ ν†µν•΄:\n",
    "- β… MDM λ¨λΈ νμΈνλ‹ μ™„λ£\n",
    "- β… Google Driveμ— μ²΄ν¬ν¬μΈνΈ μλ™ μ €μ¥\n",
    "- β… EDGE μµμ ν™” (μ–‘μν™”) μ μ©\n",
    "- β… ONNX ν•μ‹μΌλ΅ λ¨λΈ λ‚΄λ³΄λ‚΄κΈ°\n",
    "\n",
    "### λ‹¤μ λ‹¨κ³„\n",
    "1. μ €μ¥λ μ²΄ν¬ν¬μΈνΈλ¥Ό λ΅μ»¬ ν”„λ΅μ νΈμ—μ„ μ‚¬μ©\n",
    "2. ONNX λ¨λΈμ„ μ—£μ§€ λ””λ°”μ΄μ¤μ— λ°°ν¬\n",
    "3. μ¶”κ°€ νμΈνλ‹ μ§„ν–‰"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "MDM_Finetuning_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
