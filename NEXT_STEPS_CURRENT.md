# 다음 단계 가이드 (현재 상태 기준)

## ✅ 완료된 작업

1. **프론트엔드**
   - ✅ React/Vite 프로젝트 설정
   - ✅ 3D 뷰어 (Three.js)
   - ✅ 타임라인 UI
   - ✅ 오디오 업로드 및 분석 UI
   - ✅ 프롬프트 입력 UI
   - ✅ API 클라이언트 (`frontend/services/api.js`)

2. **백엔드**
   - ✅ FastAPI 서버 구조
   - ✅ 오디오 분석 (librosa) - 실제 작동
   - ✅ MDM 통합 코드 작성
   - ✅ 의존성 설치 (CLIP, smplx, SMPL, spaCy)
   - ✅ API 엔드포인트 구현

3. **MDM 모델**
   - ✅ 모델 파일 다운로드 완료
   - ✅ 통합 코드 작성 완료
   - ⚠️ 데이터셋 문제로 실제 로드는 아직 미완성 (모의 모드로 작동)

---

## 🎯 다음 단계 (우선순위 순)

### 1. 프론트엔드-백엔드 통합 테스트 (즉시)

**목표**: 전체 플로우가 제대로 작동하는지 확인

#### 1.1 서버 실행 확인
```bash
# 백엔드 서버 실행
cd backend
python3.12 main.py

# 프론트엔드 실행 (다른 터미널)
cd ..
npm run dev
```

#### 1.2 기본 통신 테스트
- [ ] 프론트엔드에서 백엔드 health check
- [ ] 오디오 파일 업로드 및 분석 테스트
- [ ] 프롬프트 입력 및 모션 생성 요청 테스트
- [ ] 상태 폴링 및 결과 표시 테스트

#### 1.3 문제 해결
- CORS 오류 확인
- API 엔드포인트 경로 확인
- 데이터 포맷 일치 확인

---

### 2. 모션 데이터 포맷 및 변환 (중요)

**목표**: MDM이 생성한 모션 데이터를 프론트엔드에서 표시 가능한 형식으로 변환

#### 2.1 모션 데이터 구조 정의
```python
# backend/services/motion_generator.py에 추가
def format_motion_for_frontend(motion_data):
    """
    MDM 출력을 프론트엔드 형식으로 변환
    - HumanML3D 벡터 → XYZ 좌표
    - 프레임별 관절 위치
    - 타임스탬프 추가
    """
    pass
```

#### 2.2 프론트엔드 모션 로더
```javascript
// Sota_KPop_Studio.jsx에 추가
const loadMotionData = (motionData) => {
  // 백엔드에서 받은 모션 데이터를 Three.js 형식으로 변환
  // 타임라인에 표시
  // 3D 뷰어에 로드
}
```

#### 2.3 테스트
- [ ] 모의 모션 데이터로 프론트엔드 표시 테스트
- [ ] 타임라인 동기화 확인
- [ ] 3D 뷰어에서 재생 확인

---

### 3. 오디오-모션 동기화 (중요)

**목표**: 음악 비트와 안무 동작을 정확히 동기화

#### 3.1 비트 기반 모션 조정
```python
# backend/services/motion_generator.py
def sync_motion_to_beats(motion_data, beats, tempo):
    """
    모션을 오디오 비트에 맞춰 조정
    - 비트 타임스탬프에 맞춰 모션 키프레임 조정
    - 에너지 레벨에 따른 모션 강도 조정
    """
    pass
```

#### 3.2 프론트엔드 동기화
```javascript
// 오디오 재생과 모션 재생을 동기화
const syncAudioAndMotion = () => {
  // 오디오 currentTime과 모션 프레임 매핑
  // 비트에 맞춰 모션 강조
}
```

---

### 4. 실제 MDM 모델 사용 (선택사항)

**목표**: 실제 MDM 모델로 모션 생성

#### 4.1 데이터셋 문제 해결
- HumanML3D 데이터셋 다운로드 (선택사항)
- 또는 더미 데이터셋으로 모델 구조만 테스트

#### 4.2 모델 로드 및 생성 테스트
```python
# 실제 MDM 모델이 로드되면
integration = MDMIntegration(model_path)
if integration.load_model():
    motion = integration.generate("a person dancing", length=10.0)
```

---

### 5. K-pop 스타일 파인튜닝 준비 (장기)

**목표**: K-pop 안무에 특화된 모델 학습

#### 5.1 데이터 수집
- K-pop 안무 영상 수집
- 포즈 추정 (MediaPipe/OpenPose)
- 모션 데이터 추출

#### 5.2 파인튜닝
- MDM 모델을 K-pop 데이터로 파인튜닝
- 스타일 분류기 학습
- 반응 예측 모델 학습

---

## 🚀 즉시 시작할 수 있는 작업

### 작업 1: 통합 테스트 (30분)

```bash
# 1. 백엔드 서버 실행
cd backend
python3.12 main.py

# 2. 프론트엔드 실행 (새 터미널)
cd ..
npm run dev

# 3. 브라우저에서 테스트
# http://localhost:5173
# - 오디오 파일 업로드
# - 프롬프트 입력
# - 생성 버튼 클릭
# - 결과 확인
```

### 작업 2: 모션 데이터 포맷 정의 (1시간)

1. 백엔드에서 반환할 모션 데이터 구조 정의
2. 프론트엔드에서 기대하는 형식 정의
3. 변환 함수 작성

### 작업 3: 오디오-모션 동기화 (2-3시간)

1. 비트 정보를 모션 생성에 반영
2. 프론트엔드에서 오디오와 모션 동시 재생
3. 동기화 확인

---

## 📝 체크리스트

### 즉시 확인
- [ ] 백엔드 서버가 정상 실행되는가?
- [ ] 프론트엔드가 백엔드에 연결되는가?
- [ ] 오디오 분석이 작동하는가?
- [ ] API 요청/응답이 올바른가?

### 다음 구현
- [ ] 모션 데이터 포맷 정의
- [ ] 모션 데이터 변환 함수
- [ ] 프론트엔드 모션 로더
- [ ] 오디오-모션 동기화

### 장기 목표
- [ ] 실제 MDM 모델 사용
- [ ] K-pop 데이터 수집
- [ ] 모델 파인튜닝

---

## 💡 팁

1. **단계별 진행**: 한 번에 모든 것을 구현하려 하지 말고, 하나씩 테스트하며 진행
2. **모의 모드 활용**: 실제 MDM이 작동하지 않아도 모의 모드로 프론트엔드 개발 가능
3. **로그 확인**: 백엔드와 프론트엔드 콘솔 로그를 확인하여 문제 파악
4. **API 문서**: `http://localhost:8000/docs`에서 API 테스트 가능

---

## 🔗 관련 문서

- `QUICK_START.md` - 빠른 시작 가이드
- `USER_FLOW_CHECKLIST.md` - 사용자 플로우 확인
- `MDM_INTEGRATION_STEPS.md` - MDM 통합 단계
- `INSTALL_MDM_DEPS.md` - MDM 의존성 설치

