"""
μ²΄ν¬ν¬μΈνΈ μ €μ¥/λ΅λ“ μ ν‹Έλ¦¬ν‹°
Colab ν™κ²½μ—μ„ Google Driveμ™€ νΈν™λλ„λ΅ μ„¤κ³„
"""
import os
import json
import torch
from pathlib import Path
from typing import Dict, Optional, Any
from datetime import datetime


class CheckpointManager:
    """
    λ¨λΈ μ²΄ν¬ν¬μΈνΈλ¥Ό κ΄€λ¦¬ν•©λ‹λ‹¤.
    Google Driveμ™€μ λ™κΈ°ν™”λ¥Ό μ§€μ›ν•©λ‹λ‹¤.
    """

    def __init__(
        self,
        checkpoint_dir: str = "checkpoints",
        max_checkpoints: int = 5,
        google_drive_sync: bool = False,
        drive_folder: str = "MDM_Checkpoints"
    ):
        """
        μ²΄ν¬ν¬μΈνΈ λ§¤λ‹μ € μ΄κΈ°ν™”

        Args:
            checkpoint_dir: μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ””λ ‰ν† λ¦¬
            max_checkpoints: μ μ§€ν•  μµλ€ μ²΄ν¬ν¬μΈνΈ μ
            google_drive_sync: Google Drive λ™κΈ°ν™” μ‚¬μ© μ—¬λ¶€
            drive_folder: Google Drive ν΄λ” μ΄λ¦„
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.max_checkpoints = max_checkpoints
        self.google_drive_sync = google_drive_sync
        self.drive_folder = drive_folder

        # Colab ν™κ²½ κ°μ§€
        self.is_colab = self._detect_colab()

        # Google Drive λ§μ΄νΈ ν™•μΈ
        if self.is_colab and self.google_drive_sync:
            self.drive_checkpoint_dir = self._setup_drive_sync()
        else:
            self.drive_checkpoint_dir = None

    def _detect_colab(self) -> bool:
        """Colab ν™κ²½μΈμ§€ κ°μ§€"""
        try:
            import google.colab
            return True
        except ImportError:
            return False

    def _setup_drive_sync(self) -> Optional[Path]:
        """Google Drive λ™κΈ°ν™” μ„¤μ •"""
        try:
            from google.colab import drive

            # Drive λ§μ΄νΈ
            mount_point = Path("/content/drive")
            if not mount_point.exists():
                print("π“‚ Google Drive λ§μ΄νΈ μ¤‘...")
                drive.mount(str(mount_point))

            # μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬ μƒμ„±
            drive_dir = mount_point / "MyDrive" / self.drive_folder
            drive_dir.mkdir(parents=True, exist_ok=True)

            print(f"β… Google Drive λ™κΈ°ν™” ν™μ„±ν™”: {drive_dir}")
            return drive_dir

        except Exception as e:
            print(f"β οΈ  Google Drive λ™κΈ°ν™” μ„¤μ • μ‹¤ν¨: {e}")
            return None

    def save_checkpoint(
        self,
        model: torch.nn.Module,
        optimizer: Optional[torch.optim.Optimizer] = None,
        epoch: int = 0,
        step: int = 0,
        loss: float = 0.0,
        metrics: Optional[Dict[str, Any]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        checkpoint_name: Optional[str] = None
    ) -> str:
        """
        μ²΄ν¬ν¬μΈνΈ μ €μ¥

        Args:
            model: μ €μ¥ν•  λ¨λΈ
            optimizer: μµν‹°λ§μ΄μ € (μ„ νƒμ‚¬ν•­)
            epoch: μ—ν­ λ²νΈ
            step: μ¤ν… λ²νΈ
            loss: ν„μ¬ μ†μ‹¤κ°’
            metrics: ν‰κ°€ μ§€ν‘λ“¤
            metadata: μ¶”κ°€ λ©”νƒ€λ°μ΄ν„°
            checkpoint_name: μ²΄ν¬ν¬μΈνΈ μ΄λ¦„ (Noneμ΄λ©΄ μλ™ μƒμ„±)

        Returns:
            str: μ €μ¥λ μ²΄ν¬ν¬μΈνΈ κ²½λ΅
        """
        if checkpoint_name is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_name = f"checkpoint_epoch{epoch}_step{step}_{timestamp}.pt"

        checkpoint_path = self.checkpoint_dir / checkpoint_name

        # μ²΄ν¬ν¬μΈνΈ λ°μ΄ν„° κµ¬μ„±
        checkpoint_data = {
            'epoch': epoch,
            'step': step,
            'model_state_dict': model.state_dict(),
            'loss': loss,
            'timestamp': datetime.now().isoformat(),
        }

        # μµν‹°λ§μ΄μ € μƒνƒ μ €μ¥
        if optimizer is not None:
            checkpoint_data['optimizer_state_dict'] = optimizer.state_dict()

        # λ©”νΈλ¦­ μ €μ¥
        if metrics is not None:
            checkpoint_data['metrics'] = metrics

        # λ©”νƒ€λ°μ΄ν„° μ €μ¥
        if metadata is not None:
            checkpoint_data['metadata'] = metadata

        # λ΅μ»¬μ— μ €μ¥
        try:
            torch.save(checkpoint_data, checkpoint_path)
            print(f"β… μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ™„λ£: {checkpoint_path}")

            # λ©”νƒ€μ •λ³΄ JSON νμΌ μ €μ¥
            meta_path = checkpoint_path.with_suffix('.json')
            with open(meta_path, 'w') as f:
                json.dump({
                    'epoch': epoch,
                    'step': step,
                    'loss': float(loss),
                    'metrics': metrics,
                    'metadata': metadata,
                    'timestamp': checkpoint_data['timestamp']
                }, f, indent=2)

        except Exception as e:
            print(f"β μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨: {e}")
            raise

        # Google Driveμ— λ°±μ—…
        if self.drive_checkpoint_dir is not None:
            try:
                drive_path = self.drive_checkpoint_dir / checkpoint_name
                torch.save(checkpoint_data, drive_path)

                drive_meta_path = drive_path.with_suffix('.json')
                with open(drive_meta_path, 'w') as f:
                    json.dump({
                        'epoch': epoch,
                        'step': step,
                        'loss': float(loss),
                        'metrics': metrics,
                        'metadata': metadata,
                        'timestamp': checkpoint_data['timestamp']
                    }, f, indent=2)

                print(f"β… Google Drive λ°±μ—… μ™„λ£: {drive_path}")
            except Exception as e:
                print(f"β οΈ  Google Drive λ°±μ—… μ‹¤ν¨: {e}")

        # μ¤λλ μ²΄ν¬ν¬μΈνΈ μ •λ¦¬
        self._cleanup_old_checkpoints()

        return str(checkpoint_path)

    def load_checkpoint(
        self,
        checkpoint_path: str,
        model: torch.nn.Module,
        optimizer: Optional[torch.optim.Optimizer] = None,
        device: str = 'cpu'
    ) -> Dict[str, Any]:
        """
        μ²΄ν¬ν¬μΈνΈ λ΅λ“

        Args:
            checkpoint_path: μ²΄ν¬ν¬μΈνΈ νμΌ κ²½λ΅
            model: λ΅λ“ν•  λ¨λΈ
            optimizer: μµν‹°λ§μ΄μ € (μ„ νƒμ‚¬ν•­)
            device: λ””λ°”μ΄μ¤ ('cpu' λλ” 'cuda')

        Returns:
            Dict: μ²΄ν¬ν¬μΈνΈ μ •λ³΄ (epoch, step, loss λ“±)
        """
        checkpoint_path = Path(checkpoint_path)

        # Google Driveμ—μ„ λ¨Όμ € μ°ΎκΈ°
        if self.drive_checkpoint_dir is not None:
            drive_path = self.drive_checkpoint_dir / checkpoint_path.name
            if drive_path.exists():
                checkpoint_path = drive_path
                print(f"π“‚ Google Driveμ—μ„ μ²΄ν¬ν¬μΈνΈ λ΅λ“: {drive_path}")

        if not checkpoint_path.exists():
            raise FileNotFoundError(f"μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤: {checkpoint_path}")

        try:
            # μ²΄ν¬ν¬μΈνΈ λ΅λ“
            checkpoint = torch.load(checkpoint_path, map_location=device)

            # λ¨λΈ μƒνƒ λ΅λ“
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"β… λ¨λΈ μƒνƒ λ΅λ“ μ™„λ£")

            # μµν‹°λ§μ΄μ € μƒνƒ λ΅λ“
            if optimizer is not None and 'optimizer_state_dict' in checkpoint:
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                print(f"β… μµν‹°λ§μ΄μ € μƒνƒ λ΅λ“ μ™„λ£")

            # μ •λ³΄ λ°ν™
            info = {
                'epoch': checkpoint.get('epoch', 0),
                'step': checkpoint.get('step', 0),
                'loss': checkpoint.get('loss', 0.0),
                'metrics': checkpoint.get('metrics', {}),
                'metadata': checkpoint.get('metadata', {}),
                'timestamp': checkpoint.get('timestamp', '')
            }

            print(f"β… μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ™„λ£: Epoch {info['epoch']}, Step {info['step']}, Loss {info['loss']:.4f}")
            return info

        except Exception as e:
            print(f"β μ²΄ν¬ν¬μΈνΈ λ΅λ“ μ‹¤ν¨: {e}")
            raise

    def load_latest_checkpoint(
        self,
        model: torch.nn.Module,
        optimizer: Optional[torch.optim.Optimizer] = None,
        device: str = 'cpu',
        from_drive: bool = False
    ) -> Optional[Dict[str, Any]]:
        """
        κ°€μ¥ μµκ·Ό μ²΄ν¬ν¬μΈνΈ λ΅λ“

        Args:
            model: λ΅λ“ν•  λ¨λΈ
            optimizer: μµν‹°λ§μ΄μ € (μ„ νƒμ‚¬ν•­)
            device: λ””λ°”μ΄μ¤
            from_drive: Google Driveμ—μ„ λ΅λ“ν• μ§€ μ—¬λ¶€

        Returns:
            Optional[Dict]: μ²΄ν¬ν¬μΈνΈ μ •λ³΄ (μ—†μΌλ©΄ None)
        """
        # μ²΄ν¬ν¬μΈνΈ λ””λ ‰ν† λ¦¬ μ„ νƒ
        if from_drive and self.drive_checkpoint_dir is not None:
            search_dir = self.drive_checkpoint_dir
        else:
            search_dir = self.checkpoint_dir

        # .pt νμΌ μ°ΎκΈ°
        checkpoints = list(search_dir.glob("*.pt"))

        if not checkpoints:
            print("β οΈ  μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤.")
            return None

        # μµμ‹  νμΌ μ°ΎκΈ° (μμ • μ‹κ°„ κΈ°μ¤€)
        latest_checkpoint = max(checkpoints, key=lambda p: p.stat().st_mtime)

        print(f"π“‚ μµμ‹  μ²΄ν¬ν¬μΈνΈ λ°κ²¬: {latest_checkpoint}")
        return self.load_checkpoint(str(latest_checkpoint), model, optimizer, device)

    def _cleanup_old_checkpoints(self):
        """μ¤λλ μ²΄ν¬ν¬μΈνΈ μ‚­μ """
        checkpoints = sorted(
            self.checkpoint_dir.glob("*.pt"),
            key=lambda p: p.stat().st_mtime,
            reverse=True
        )

        # max_checkpoints μ΄μƒμ΄λ©΄ μ¤λλ κ²ƒ μ‚­μ 
        for checkpoint in checkpoints[self.max_checkpoints:]:
            try:
                checkpoint.unlink()
                # λ©”νƒ€ νμΌλ„ μ‚­μ 
                meta_file = checkpoint.with_suffix('.json')
                if meta_file.exists():
                    meta_file.unlink()
                print(f"π—‘οΈ  μ¤λλ μ²΄ν¬ν¬μΈνΈ μ‚­μ : {checkpoint.name}")
            except Exception as e:
                print(f"β οΈ  μ²΄ν¬ν¬μΈνΈ μ‚­μ  μ‹¤ν¨: {e}")

    def list_checkpoints(self, from_drive: bool = False) -> list:
        """
        μ €μ¥λ μ²΄ν¬ν¬μΈνΈ λ©λ΅ λ°ν™

        Args:
            from_drive: Google Driveμ—μ„ λ©λ΅ κ°€μ Έμ¤κΈ°

        Returns:
            list: μ²΄ν¬ν¬μΈνΈ μ •λ³΄ λ¦¬μ¤νΈ
        """
        if from_drive and self.drive_checkpoint_dir is not None:
            search_dir = self.drive_checkpoint_dir
        else:
            search_dir = self.checkpoint_dir

        checkpoints = []
        for pt_file in sorted(search_dir.glob("*.pt"), key=lambda p: p.stat().st_mtime, reverse=True):
            meta_file = pt_file.with_suffix('.json')
            if meta_file.exists():
                with open(meta_file, 'r') as f:
                    info = json.load(f)
                    info['path'] = str(pt_file)
                    checkpoints.append(info)
            else:
                checkpoints.append({
                    'path': str(pt_file),
                    'name': pt_file.name
                })

        return checkpoints


# νΈμ ν•¨μλ“¤
def save_model_checkpoint(
    model: torch.nn.Module,
    save_path: str,
    **kwargs
) -> str:
    """
    κ°„λ‹¨ν• μ²΄ν¬ν¬μΈνΈ μ €μ¥

    Args:
        model: μ €μ¥ν•  λ¨λΈ
        save_path: μ €μ¥ κ²½λ΅
        **kwargs: CheckpointManager.save_checkpointμ— μ „λ‹¬λ  μ¶”κ°€ μΈμ
    """
    manager = CheckpointManager()
    return manager.save_checkpoint(model, checkpoint_name=save_path, **kwargs)


def load_model_checkpoint(
    model: torch.nn.Module,
    checkpoint_path: str,
    device: str = 'cpu',
    **kwargs
) -> Dict[str, Any]:
    """
    κ°„λ‹¨ν• μ²΄ν¬ν¬μΈνΈ λ΅λ“

    Args:
        model: λ΅λ“ν•  λ¨λΈ
        checkpoint_path: μ²΄ν¬ν¬μΈνΈ κ²½λ΅
        device: λ””λ°”μ΄μ¤
        **kwargs: CheckpointManager.load_checkpointμ— μ „λ‹¬λ  μ¶”κ°€ μΈμ
    """
    manager = CheckpointManager()
    return manager.load_checkpoint(checkpoint_path, model, device=device, **kwargs)


if __name__ == "__main__":
    # ν…μ¤νΈ
    print("μ²΄ν¬ν¬μΈνΈ λ§¤λ‹μ € ν…μ¤νΈ")

    manager = CheckpointManager(
        checkpoint_dir="test_checkpoints",
        max_checkpoints=3,
        google_drive_sync=False
    )

    # λ”λ―Έ λ¨λΈ μƒμ„±
    model = torch.nn.Linear(10, 5)
    optimizer = torch.optim.Adam(model.parameters())

    # μ²΄ν¬ν¬μΈνΈ μ €μ¥ ν…μ¤νΈ
    manager.save_checkpoint(
        model=model,
        optimizer=optimizer,
        epoch=1,
        step=100,
        loss=0.5,
        metrics={'accuracy': 0.85}
    )

    # μ²΄ν¬ν¬μΈνΈ λ©λ΅
    checkpoints = manager.list_checkpoints()
    print(f"\nμ €μ¥λ μ²΄ν¬ν¬μΈνΈ: {len(checkpoints)}κ°")
    for cp in checkpoints:
        print(f"  - {cp.get('path', 'N/A')}")
